Third generation sequencing technologies have enabled the production of long reads ranging from tens to thousands of bases in length \cite{Pollard2018}, and have shown promise in resolving many challenges in genomics and transcriptomics \cite{Bolisetty2015, Byrne2017, DeCoster2019, Liu2019, Mantere2019, Nurk2021}. In particular, long-read technologies enable greater insight into the transcriptome and its complexity, which is crucial in understanding the functioning of cells and their biological processes. These technologies allow accurate detection of full-length transcript isoforms and novel splice junctions while mitigating biases associated with short-read technologies, enabling more accurate quantification of reference and novel isoforms. Nevertheless, biases are still present in long-read technologies, albeit to a lesser extent. 

This project focuses on a particular bias present in long-read \gls{rnaseq} referred to as \textit{degradation bias}. This bias arises due to the fact that from the time a transcript is synthesized to when it is sequenced, it is subject to multiple factors that results in its degradation, primarily from the 5' end of the transcript. Consequently, the observed reads are often truncated and \textit{degraded}, potentially resulting in ambiguity in read assignment to transcript isoforms. This, in turn, leads to erroneous quantification estimates. As degradation bias in long-read \gls{rnaseq} has not been extensively covered in existing literature, we attempt to do so here by characterising the bias and its effects on quantification from long-read \gls{rnaseq}, and developing a framework to model and correct such bias by producing \textit{degradation-aware quantification estimates}. We incorporate this model into \texttt{bambu}, a tool for context-aware transcript discovery and quantification from long-read \gls{rnaseq}. 

To evaluate quantification estimates from \gls{rnaseq}, experimental datasets with known ground truth or simulated datasets are typically used, and estimates are evaluated based on their concordance with the ground truth. Here, we generate simulated long-read \gls{rnaseq} data as experimental datasets with known ground truth are unavailable. In order to test our bias models, we develop an approach to generating novel transcript models that is capable of generating adversarial transcript models where not correcting for degradation bias can lead to significantly erroneous quantification estimates. For evaluating degradation-aware quantification estimates, we employ several reference-based and reference-free metrics that measure the concordance of estimates with the ground truth along with the variance of estimates acrosss technical replicates.   

\section{Review}

Here, we review various concepts and existing literature relevant to our aim of modeling bias in long-read \gls{rnaseq}. We first examine (i) biases in short-read \gls{rnaseq} technologies and how they are accounted for by existing methods, which provide some ideas on how to handle biases in long-read \gls{rnaseq}. Next, we review (ii) long-read \gls{rnaseq} technologies and how they mitigate biases in (i), and (iii) biases that long-read technologies themselves possess. 

\subsection{Bias in short-read \gls{rnaseq}}

Short-read \gls{rnaseq} technologies enable deep sequencing of highly accurate short reads, and has been the dominant technology for profiling the transcriptome since its popularisation in the early 2010s \cite{Lowe2017}. Typically, library preparation protocol for an \gls{rnaseq} experiment following \gls{rna} extraction involves \gls{rna} fragmentation, followed by the use of random hexamer primers for priming of the fragments to synthesize one strand of \gls{cdna}. After second strand synthesis, the resulting double stranded \gls{cdna} are size-selected and amplified via \gls{pcr} amplification to generate enough \gls{cdna} for sequencing \cite{Marguerat2010}.  

Biases in short-read \gls{rnaseq} have been extensively studied \cite{Hansen2010, Li2010, Roberts2011, Benjamini2012, Love2016}, and can often be traced back to specific steps in the protocol described above. For instance, \cite{Hansen2010} showed that random hexamer primers induces bias in the nucleotide composition of the reads and results in non-uniform representation of reads across the length of the transcript. Next, size selection of fragments results in an over-representation of fragments of a certain length, while \gls{rna} degradation and \gls{mrna} selection can lead to over-representation of fragments that are located towards either the beginning or end of the transcript \cite{Roberts2011, Love2016}.  \gls{pcr} amplification before sequencing also introduces bias by preferential amplification of fragments with certain GC content \cite{Benjamini2012, Love2016}. The combination of these biases affect quantification estimates, and if not corrected for, lead to erroneous estimates \cite{Roberts2011, Love2016}. 

Methods to address these biases and provide bias-aware quantification estimates can be categorised into two broad classes. The first class of methods involve changes in library preparation methods to reduce bias from their source of origin. The second class of methods involve modeling and correcting the bias \textit{in silico}. 

\subsection{Long-read technologies}

\lipsum[1]

\subsection{Bias in long-read \gls{rnaseq}}

\lipsum[3]

\section{Organisation}

The chapters of this thesis are organised as follows:
\begin{itemize}
    \item In Chapter 2, we review methods to evaluate \gls{rnaseq} quantification, including reference-based metrics where the ground truth is known, and reference-free metrics which describe the variance of estimates across technical replicates. 
    \item In Chapter 3, we develop methods to generate novel transcript models for simulation, including a handcrafting approach that is splice-aware, and an experimental approach that involves deep generative modeling.
    \item In Chapter 4, we examine and characterise degradation bias in long-read \gls{rnaseq} across multiple samples and protocols, demonstrating how it can lead to erroneous quantification estimates. We develop a model that corrects for degradation bias, and demonstrate that it improves quantification estimates on data simulated with approaches in Chapter 3 based on evaluation metrics in Chapter 2. 
    \item In Chapter $n$, we summarise the ideas of the thesis and discuss potential directions of future work. 
\end{itemize}